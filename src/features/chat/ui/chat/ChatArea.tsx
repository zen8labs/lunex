import { useState } from 'react';
import { ChatMessages } from './ChatMessages';
import { ChatInput } from './ChatInput';
import { AgentChatHistoryDialog } from '@/features/agent';
import { ImagePreviewDialog } from '@/ui/molecules/ImagePreviewDialog';
import { useMessages } from '../../hooks/useMessages';
import { useWorkspaces } from '@/features/workspace';
import { useAppDispatch, useAppSelector } from '@/app/hooks';
import { MAX_MESSAGE_LENGTH } from '@/lib/constants';
import { useTranslation } from 'react-i18next';
import { Sparkles } from 'lucide-react';
import { sendMessage, editAndResendMessage } from '../../state/messages';
import { createChat } from '../../state/chatsSlice';
import {
  setLoading,
  clearInput,
  setInput,
  setAttachedFiles,
} from '../../state/chatInputSlice';
import { showError } from '@/features/notifications/state/notificationSlice';
import { setAgentChatHistoryDrawerOpen } from '@/features/ui/state/uiSlice';
import { invokeCommand, TauriCommands } from '@/lib/tauri';
import { messagesApi } from '../../state/messagesApi';
import { useGetLLMConnectionsQuery } from '@/features/llm';

export function ChatArea() {
  const { t } = useTranslation(['common', 'settings']);
  const dispatch = useAppDispatch();

  // Use workspaces hook to get selectedWorkspaceId and selectedLLMConnectionId
  const { selectedWorkspace, selectedWorkspaceId, workspaceSettings } =
    useWorkspaces();

  // Get selectedChatId from Redux state
  const selectedChatId = useAppSelector((state) => state.chats.selectedChatId);

  // Get agent chat history drawer state
  const agentChatHistoryDrawerOpen = useAppSelector(
    (state) => state.ui.agentChatHistoryDrawerOpen
  );
  const agentChatHistorySessionId = useAppSelector(
    (state) => state.ui.agentChatHistorySessionId
  );
  const agentChatHistoryAgentId = useAppSelector(
    (state) => state.ui.agentChatHistoryAgentId
  );

  const selectedLLMConnectionId = selectedWorkspace
    ? workspaceSettings[selectedWorkspace.id]?.llmConnectionId
    : undefined;

  // Get chat input state for handleSend
  const input = useAppSelector((state) => state.chatInput.input);
  const selectedModel = useAppSelector(
    (state) => state.chatInput.selectedModel
  );
  const attachedFiles = useAppSelector(
    (state) => state.chatInput.attachedFiles
  );

  const { data: llmConnections = [] } = useGetLLMConnectionsQuery();

  // Use messages hook
  const {
    messages,
    pausedStreaming,
    isStreaming,
    isAgentStreaming,
    streamingMessageId,
    streamingError,
    timeLeft,
    handleStopStreaming,
    handleRetryStreaming,
  } = useMessages(selectedChatId);

  const [editingMessageId, setEditingMessageId] = useState<string | null>(null);

  const handleEditMessage = (messageId: string | null) => {
    if (!messageId) {
      setEditingMessageId(null);
      dispatch(clearInput());
      dispatch(setAttachedFiles([]));
      return;
    }
    const message = messages.find((m) => m.id === messageId);
    if (message) {
      setEditingMessageId(messageId);
      dispatch(setInput(message.content));

      // Restore files if available (supports both old 'images' format and new 'files' format)
      try {
        if (message.metadata) {
          const parsed = JSON.parse(message.metadata);
          // Try new format first, fallback to old format
          const fileList = parsed.files || parsed.images;
          if (Array.isArray(fileList) && fileList.length > 0) {
            const promises = fileList.map(
              async (filePath: string, index: number) => {
                try {
                  let blob: Blob;
                  let mimeType = 'application/octet-stream';
                  let extension = 'bin';

                  if (filePath.startsWith('data:')) {
                    // Handle data URL (Legacy)
                    const mimeMatch = filePath.match(/data:(.*?);/);
                    mimeType = mimeMatch ? mimeMatch[1] : mimeType;
                    extension = mimeType.split('/')[1] || extension;

                    const byteString = atob(filePath.split(',')[1]);
                    const ab = new ArrayBuffer(byteString.length);
                    const ia = new Uint8Array(ab);
                    for (let i = 0; i < byteString.length; i++) {
                      ia[i] = byteString.charCodeAt(i);
                    }
                    blob = new Blob([ab], { type: mimeType });
                  } else {
                    // Handle file path (New)
                    const { readFile } = await import('@tauri-apps/plugin-fs');
                    const bytes = await readFile(filePath);

                    const ext =
                      filePath.split('.').pop()?.toLowerCase() || 'bin';

                    // If mimeType not provided from metadata, guess from extension
                    if (mimeType === 'application/octet-stream') {
                      mimeType = (() => {
                        switch (ext) {
                          // Images
                          case 'jpg':
                          case 'jpeg':
                            return 'image/jpeg';
                          case 'png':
                            return 'image/png';
                          case 'webp':
                            return 'image/webp';
                          case 'gif':
                            return 'image/gif';
                          case 'svg':
                            return 'image/svg+xml';
                          // Documents
                          case 'pdf':
                            return 'application/pdf';
                          case 'txt':
                            return 'text/plain';
                          case 'md':
                            return 'text/markdown';
                          case 'csv':
                            return 'text/csv';
                          // Audio
                          case 'mp3':
                            return 'audio/mpeg';
                          case 'wav':
                            return 'audio/wav';
                          case 'ogg':
                            return 'audio/ogg';
                          // Video
                          case 'mp4':
                            return 'video/mp4';
                          case 'webm':
                            return 'video/webm';
                          case 'mov':
                            return 'video/quicktime';
                          default:
                            return 'application/octet-stream';
                        }
                      })();
                    }
                    extension = ext;
                    blob = new Blob([bytes], { type: mimeType });
                  }

                  return new File([blob], `file-${index}.${extension}`, {
                    type: mimeType,
                  });
                } catch (e) {
                  console.error('Failed to restore file', e);
                  return null;
                }
              }
            );

            Promise.all(promises).then((results) => {
              const validFiles = results.filter((f): f is File => f !== null);
              if (validFiles.length > 0) {
                dispatch(setAttachedFiles(validFiles));
              } else {
                dispatch(setAttachedFiles([]));
              }
            });
          } else {
            dispatch(setAttachedFiles([]));
          }
        } else {
          dispatch(setAttachedFiles([]));
        }
      } catch (e) {
        console.error('Failed to restore images for editing', e);
        dispatch(setAttachedFiles([]));
      }
    }
  };

  const handleSend = async (overrideContent?: string, files?: string[]) => {
    // If overrideContent is provided, use it. Otherwise use state input.
    const contentToSend =
      overrideContent !== undefined ? overrideContent : input;

    const hasFiles = files && files.length > 0;
    const userInput = contentToSend.trim();

    if ((!userInput && !hasFiles) || !selectedWorkspace) {
      return;
    }

    let currentChatId = selectedChatId;

    // Auto-create chat if none selected
    if (!currentChatId && selectedWorkspaceId) {
      try {
        const title =
          userInput.split('\n')[0].slice(0, 50) || t('newConversation');
        const newChat = await dispatch(
          createChat({
            workspaceId: selectedWorkspaceId,
            title,
          })
        ).unwrap();
        currentChatId = newChat.id;
      } catch (error) {
        console.error('Failed to auto-create chat:', error);
        dispatch(showError(t('cannotCreateChat', { ns: 'settings' })));
        return;
      }
    }

    if (!currentChatId) {
      return;
    }

    if (userInput.length > MAX_MESSAGE_LENGTH) {
      dispatch(
        showError(
          t('messageTooLong', {
            length: contentToSend.length,
            max: MAX_MESSAGE_LENGTH,
            ns: 'chat',
          })
        )
      );
      return;
    }

    const workspaceSetting = workspaceSettings[selectedWorkspace.id];
    let llmConnectionId = workspaceSetting?.llmConnectionId;
    let modelId = selectedModel;

    if (selectedModel?.includes('::')) {
      const [connId, ...modelIdParts] = selectedModel.split('::');
      llmConnectionId = connId;
      modelId = modelIdParts.join('::');
    }

    if (!llmConnectionId) {
      dispatch(showError(t('pleaseSelectLLMConnection', { ns: 'settings' })));
      return;
    }

    const llmConnection = llmConnections.find(
      (conn) => conn.id === llmConnectionId
    );
    if (!llmConnection) {
      dispatch(showError(t('llmConnectionNotFound', { ns: 'settings' })));
      return;
    }

    if (!modelId) {
      dispatch(showError(t('pleaseSelectModel', { ns: 'settings' })));
      return;
    }

    // Track message send
    const { trackMessageSend, setLLMContext, setChatContext } =
      await import('@/lib/sentry-utils');
    trackMessageSend(
      currentChatId,
      userInput.length,
      hasFiles || attachedFiles.length > 0
    );
    setLLMContext(llmConnection.provider, modelId);
    setChatContext(currentChatId);

    // Clear input immediately for better UX
    dispatch(clearInput());
    dispatch(setLoading(true));

    // Capture editing ID and clear it immediately for better UX
    const currentEditingId = editingMessageId;
    if (currentEditingId) {
      setEditingMessageId(null);
    }

    try {
      // Send message with streaming support (streaming handled via Tauri events)
      if (currentEditingId) {
        const message = messages.find((m) => m.id === currentEditingId);
        if (message) {
          if (message.role === 'user') {
            await dispatch(
              editAndResendMessage({
                chatId: currentChatId,
                messageId: currentEditingId,
                newContent: userInput,
                files, // Pass updated files
              })
            ).unwrap();
          } else if (message.role === 'assistant') {
            await invokeCommand(TauriCommands.UPDATE_MESSAGE, {
              id: currentEditingId,
              content: userInput,
              reasoning: message.reasoning || null,
              timestamp: null,
            });
            dispatch(
              messagesApi.util.invalidateTags([
                { type: 'Message', id: `LIST_${currentChatId}` },
              ])
            );
          }
        }
      } else {
        await dispatch(
          sendMessage({
            chatId: currentChatId,
            content: userInput,
            files,
          })
        ).unwrap();
      }

      // Note: Chat last message is updated by Rust core after message completion
      // Events will handle content updates, so we don't need to update it here
    } catch (error: unknown) {
      console.error('Error sending message:', error);
      // Error message is already handled in the thunk
      // Note: Input is already cleared, which is fine for UX
    } finally {
      dispatch(setLoading(false));
    }
  };

  if (messages.length === 0) {
    // Empty state: Show slogan and center the input
    return (
      <div className="flex flex-1 flex-col items-center justify-center">
        <div className="flex flex-col items-center justify-center mb-8">
          <div className="rounded-full bg-primary/10 p-4 mb-4">
            <Sparkles className="size-8 text-primary" />
          </div>
          <h2 className="text-2xl font-semibold text-foreground mb-2">
            {t('chatSlogan', { ns: 'common' })}
          </h2>
          <p className="text-sm text-muted-foreground text-center max-w-md">
            {t('chatSloganDescription', { ns: 'common' })}
          </p>
        </div>
        <div className="w-full max-w-3xl px-4">
          <ChatInput
            selectedWorkspaceId={selectedWorkspaceId}
            selectedChatId={selectedChatId}
            selectedLLMConnectionId={selectedLLMConnectionId}
            onSend={handleSend}
            disabled={false}
            timeLeft={timeLeft}
            streamingError={selectedChatId ? streamingError : undefined}
            onRetryStreaming={handleRetryStreaming}
            isEditing={!!editingMessageId}
            onCancelEdit={() => handleEditMessage(null)}
          />
        </div>
      </div>
    );
  }

  // Has messages: Normal layout
  return (
    <>
      {/* Messages Area */}
      <ChatMessages
        messages={messages}
        isLoading={
          isStreaming &&
          !pausedStreaming[selectedChatId || ''] &&
          !isAgentStreaming
        }
        streamingMessageId={streamingMessageId}
        onCancelToolExecution={handleStopStreaming}
        onEditMessage={handleEditMessage}
      />

      {/* Input Area */}
      <ChatInput
        selectedWorkspaceId={selectedWorkspaceId}
        selectedChatId={selectedChatId}
        selectedLLMConnectionId={selectedLLMConnectionId}
        onSend={handleSend}
        disabled={false}
        dropdownDirection="up"
        timeLeft={timeLeft}
        streamingError={selectedChatId ? streamingError : undefined}
        onRetryStreaming={handleRetryStreaming}
        isEditing={!!editingMessageId}
        onCancelEdit={() => handleEditMessage(null)}
      />

      {/* Agent Chat History Dialog */}
      <AgentChatHistoryDialog
        open={agentChatHistoryDrawerOpen}
        onOpenChange={(open) =>
          dispatch(
            setAgentChatHistoryDrawerOpen({
              open,
              sessionId: null,
              agentId: null,
            })
          )
        }
        sessionId={agentChatHistorySessionId}
        agentId={agentChatHistoryAgentId}
      />
      <ImagePreviewDialog />
    </>
  );
}
